{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Iterated, own window and mirrored\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dsrus\\Desktop\\Workspace\\MTLiens\\pytorch_env\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Convert back to BGR for OpenCV display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw hand landmarks on the image\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Black on White Chunks\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "GRID_SIZE = 50\n",
    "UPDATE_FREQUENCY = 2  # Update display every 2 frames\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Create a GRID_SIZE x GRID_SIZE grid of 'O's\n",
    "    grid = np.full((GRID_SIZE, GRID_SIZE), 'O', dtype='<U1')\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                # Convert landmark coordinates to grid coordinates\n",
    "                x = int(landmark.x * GRID_SIZE)\n",
    "                y = int(landmark.y * GRID_SIZE)\n",
    "                \n",
    "                # Mark a 3x3 area around each landmark\n",
    "                for dx in [-1, 0, 1]:\n",
    "                    for dy in [-1, 0, 1]:\n",
    "                        nx, ny = x + dx, y + dy\n",
    "                        if 0 <= nx < GRID_SIZE and 0 <= ny < GRID_SIZE:\n",
    "                            grid[ny, nx] = 'X'\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % UPDATE_FREQUENCY == 0:\n",
    "        # Display the grid\n",
    "        ax.clear()\n",
    "        for i in range(GRID_SIZE):\n",
    "            for j in range(GRID_SIZE):\n",
    "                color = 'black' if grid[i, j] == 'X' else 'white'\n",
    "                ax.text(j, i, grid[i, j], ha='center', va='center', color=color, fontweight='bold')\n",
    "        ax.set_xlim(-1, GRID_SIZE)\n",
    "        ax.set_ylim(GRID_SIZE, -1)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "        plt.pause(0.01)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "hands.close()\n",
    "plt.close(fig)\n",
    "\n",
    "# Ensure the camera is released\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//4elements Game\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from playsound import playsound\n",
    "import threading\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            playsound(sound_file)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    'Fire': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "    'Air': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    'Water': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    'Earth': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# To keep track of which sounds have been played\n",
    "sound_played = {element: False for element in squares}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Convert back to BGR for OpenCV display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    for element, info in squares.items():\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "        cv2.putText(image, element, (info['position'][0] + 10, info['position'][1] + 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "            \n",
    "            # Check if hand is touching any square\n",
    "            for element, info in squares.items():\n",
    "                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "                if info['position'][0] < x < info['position'][0] + square_size and info['position'][1] < y < info['position'][1] + square_size:\n",
    "                    print(f\"Touch detected in {element} square\")\n",
    "                    if not sound_played[element]:\n",
    "                        print(f\"Attempting to play sound for {element}\")\n",
    "                        play_sound(info['sound'])\n",
    "                        sound_played[element] = True\n",
    "                else:\n",
    "                    sound_played[element] = False\n",
    "        \n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Using Winsound\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touch detected in Earth square\n",
      "Attempting to play sound for Earth\n",
      "Touch detected in Earth square\n",
      "Attempting to play sound for Earth\n",
      "Touch detected in Air square\n",
      "Attempting to play sound for Air\n",
      "Touch detected in Air square\n",
      "Attempting to play sound for Air\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    'Fire': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "    'Air': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    'Water': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    'Earth': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "# To keep track of which sounds have been played\n",
    "sound_played = {element: False for element in squares}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Convert back to BGR for OpenCV display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    for element, info in squares.items():\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "        cv2.putText(image, element, (info['position'][0] + 10, info['position'][1] + 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "            \n",
    "            # Check if hand is touching any square\n",
    "            for element, info in squares.items():\n",
    "                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "                if info['position'][0] < x < info['position'][0] + square_size and info['position'][1] < y < info['position'][1] + square_size:\n",
    "                    print(f\"Touch detected in {element} square\")\n",
    "                    if not sound_played[element]:\n",
    "                        print(f\"Attempting to play sound for {element}\")\n",
    "                        play_sound(info['sound'])\n",
    "                        sound_played[element] = True\n",
    "                else:\n",
    "                    sound_played[element] = False\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)  # Stop any ongoing sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Only 1 time sound, better interation\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touch detected in Air square\n",
      "Attempting to play sound for Air\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    'Fire': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire5.wav'},\n",
    "    'Air': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    'Water': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    'Earth': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "# To keep track of which sounds have been played and finger position\n",
    "sound_played = {element: False for element in squares}\n",
    "finger_in_box = {element: False for element in squares}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Convert back to BGR for OpenCV display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    for element, info in squares.items():\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "        cv2.putText(image, element, (info['position'][0] + 10, info['position'][1] + 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "            \n",
    "            # Check if hand is touching any square\n",
    "            for element, info in squares.items():\n",
    "                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "                if info['position'][0] < x < info['position'][0] + square_size and info['position'][1] < y < info['position'][1] + square_size:\n",
    "                    if not finger_in_box[element]:\n",
    "                        print(f\"Touch detected in {element} square\")\n",
    "                        finger_in_box[element] = True\n",
    "                        if not sound_played[element]:\n",
    "                            print(f\"Attempting to play sound for {element}\")\n",
    "                            play_sound(info['sound'])\n",
    "                            sound_played[element] = True\n",
    "                else:\n",
    "                    finger_in_box[element] = False\n",
    "                    sound_played[element] = False\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)  # Stop any ongoing sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Word Grab\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dsrus\\Desktop\\Workspace\\MTLiens\\pytorch_env\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touch detected in Air square\n",
      "Attempting to play sound for Air\n",
      "Touch detected in Air square\n",
      "Attempting to play sound for Air\n",
      "Touch detected in Air square\n",
      "Attempting to play sound for Air\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav\n",
      "Touch detected in Water square\n",
      "Attempting to play sound for Water\n",
      "Touch detected in Water square\n",
      "Attempting to play sound for Water\n",
      "Touch detected in Water square\n",
      "Attempting to play sound for Water\n",
      "Touch detected in Water square\n",
      "Attempting to play sound for Water\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    'Fire': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "    'Air': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    'Water': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    'Earth': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "# To keep track of which sounds have been played and finger position\n",
    "sound_played = {element: False for element in squares}\n",
    "finger_in_box = {element: False for element in squares}\n",
    "\n",
    "# Word grabbing and moving\n",
    "grabbed_word = None\n",
    "word_position = None\n",
    "\n",
    "def is_hand_closed(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Convert back to BGR for OpenCV display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    for element, info in squares.items():\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "        if element != grabbed_word:\n",
    "            cv2.putText(image, element, (info['position'][0] + 10, info['position'][1] + 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "            \n",
    "            index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "\n",
    "            hand_closed = is_hand_closed(hand_landmarks)\n",
    "\n",
    "            if grabbed_word:\n",
    "                if hand_closed:\n",
    "                    word_position = (x, y)\n",
    "                else:\n",
    "                    grabbed_word = None\n",
    "                    word_position = None\n",
    "            else:\n",
    "                for element, info in squares.items():\n",
    "                    if info['position'][0] < x < info['position'][0] + square_size and info['position'][1] < y < info['position'][1] + square_size:\n",
    "                        if not finger_in_box[element]:\n",
    "                            print(f\"Touch detected in {element} square\")\n",
    "                            finger_in_box[element] = True\n",
    "                            if not sound_played[element]:\n",
    "                                print(f\"Attempting to play sound for {element}\")\n",
    "                                play_sound(info['sound'])\n",
    "                                sound_played[element] = True\n",
    "                        if hand_closed and not grabbed_word:\n",
    "                            grabbed_word = element\n",
    "                            word_position = (x, y)\n",
    "                    else:\n",
    "                        finger_in_box[element] = False\n",
    "                        sound_played[element] = False\n",
    "\n",
    "    # Draw grabbed word\n",
    "    if grabbed_word and word_position:\n",
    "        cv2.putText(image, grabbed_word, word_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)  # Stop any ongoing sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Word drop correct placement\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    'Fire': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "    'Air': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    'Water': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    'Earth': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "# To keep track of which sounds have been played and finger position\n",
    "sound_played = {element: False for element in squares}\n",
    "finger_in_box = {element: False for element in squares}\n",
    "last_sound_time = {element: 0 for element in squares}\n",
    "\n",
    "# Word grabbing and moving\n",
    "grabbed_word = None\n",
    "word_positions = {element: info['position'] for element, info in squares.items()}\n",
    "\n",
    "def is_hand_closed(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Convert back to BGR for OpenCV display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    for element, info in squares.items():\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "            \n",
    "            index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "\n",
    "            hand_closed = is_hand_closed(hand_landmarks)\n",
    "\n",
    "            if grabbed_word:\n",
    "                if hand_closed:\n",
    "                    word_positions[grabbed_word] = (x, y)\n",
    "                else:\n",
    "                    grabbed_word = None\n",
    "            else:\n",
    "                for element, info in squares.items():\n",
    "                    if info['position'][0] < x < info['position'][0] + square_size and info['position'][1] < y < info['position'][1] + square_size:\n",
    "                        current_time = time.time()\n",
    "                        if not finger_in_box[element]:\n",
    "                            print(f\"Touch detected in {element} square\")\n",
    "                            finger_in_box[element] = True\n",
    "                            if current_time - last_sound_time[element] > 1:  # 1 second cooldown\n",
    "                                print(f\"Attempting to play sound for {element}\")\n",
    "                                play_sound(info['sound'])\n",
    "                                last_sound_time[element] = current_time\n",
    "                        if hand_closed and not grabbed_word:\n",
    "                            grabbed_word = element\n",
    "                    else:\n",
    "                        finger_in_box[element] = False\n",
    "\n",
    "    # Draw words at their current positions\n",
    "    for element, position in word_positions.items():\n",
    "        cv2.putText(image, element, position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)  # Stop any ongoing sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Better center words\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    'Fire': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "    'Air': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    'Water': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    'Earth': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "# To keep track of which sounds have been played and finger position\n",
    "sound_played = {element: False for element in squares}\n",
    "finger_in_box = {element: False for element in squares}\n",
    "last_sound_time = {element: 0 for element in squares}\n",
    "\n",
    "# Word grabbing and moving\n",
    "grabbed_word = None\n",
    "\n",
    "# Function to get centered text position\n",
    "def get_centered_text_position(text, box_position, box_size):\n",
    "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "    text_x = box_position[0] + (box_size - text_size[0]) // 2\n",
    "    text_y = box_position[1] + (box_size + text_size[1]) // 2\n",
    "    return (text_x, text_y)\n",
    "\n",
    "# Initialize word positions at the center of each box\n",
    "word_positions = {element: get_centered_text_position(element, info['position'], square_size) for element, info in squares.items()}\n",
    "\n",
    "def is_hand_closed(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Convert back to BGR for OpenCV display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    for element, info in squares.items():\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "            \n",
    "            index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "\n",
    "            hand_closed = is_hand_closed(hand_landmarks)\n",
    "\n",
    "            if grabbed_word:\n",
    "                if hand_closed:\n",
    "                    word_positions[grabbed_word] = (x, y)\n",
    "                else:\n",
    "                    grabbed_word = None\n",
    "            else:\n",
    "                for element, info in squares.items():\n",
    "                    if info['position'][0] < x < info['position'][0] + square_size and info['position'][1] < y < info['position'][1] + square_size:\n",
    "                        current_time = time.time()\n",
    "                        if not finger_in_box[element]:\n",
    "                            print(f\"Touch detected in {element} square\")\n",
    "                            finger_in_box[element] = True\n",
    "                            if current_time - last_sound_time[element] > 1:  # 1 second cooldown\n",
    "                                print(f\"Attempting to play sound for {element}\")\n",
    "                                play_sound(info['sound'])\n",
    "                                last_sound_time[element] = current_time\n",
    "                        if hand_closed and not grabbed_word:\n",
    "                            grabbed_word = element\n",
    "                    else:\n",
    "                        finger_in_box[element] = False\n",
    "\n",
    "    # Draw words at their current positions\n",
    "    for element, position in word_positions.items():\n",
    "        cv2.putText(image, element, position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)  # Stop any ongoing sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Gold creation script\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    'Fire': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "    'Air': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    'Water': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    'Earth': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# Define gold box\n",
    "gold_box = {'color': (0, 215, 255), 'position': ((width - square_size) // 2, height - square_size)}\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "# To keep track of which sounds have been played and finger position\n",
    "sound_played = {element: False for element in squares}\n",
    "finger_in_box = {element: False for element in squares}\n",
    "last_sound_time = {element: 0 for element in squares}\n",
    "\n",
    "# Word grabbing and moving\n",
    "grabbed_word = None\n",
    "\n",
    "# Function to get centered text position\n",
    "def get_centered_text_position(text, box_position, box_size):\n",
    "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "    text_x = box_position[0] + (box_size - text_size[0]) // 2\n",
    "    text_y = box_position[1] + (box_size + text_size[1]) // 2\n",
    "    return (text_x, text_y)\n",
    "\n",
    "# Initialize word positions at the center of each box\n",
    "word_positions = {element: get_centered_text_position(element, info['position'], square_size) for element, info in squares.items()}\n",
    "\n",
    "def is_hand_closed(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "def is_point_in_box(point, box_position, box_size):\n",
    "    return (box_position[0] < point[0] < box_position[0] + box_size and\n",
    "            box_position[1] < point[1] < box_position[1] + box_size)\n",
    "\n",
    "gold_achieved = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Convert back to BGR for OpenCV display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    for element, info in squares.items():\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "\n",
    "    # Draw gold box\n",
    "    overlay = image.copy()\n",
    "    cv2.rectangle(overlay, gold_box['position'], (gold_box['position'][0] + square_size, gold_box['position'][1] + square_size), gold_box['color'], -1)\n",
    "    cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "            \n",
    "            index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "\n",
    "            hand_closed = is_hand_closed(hand_landmarks)\n",
    "\n",
    "            if grabbed_word:\n",
    "                if hand_closed:\n",
    "                    word_positions[grabbed_word] = (x, y)\n",
    "                else:\n",
    "                    grabbed_word = None\n",
    "            else:\n",
    "                for element, info in squares.items():\n",
    "                    if is_point_in_box((x, y), info['position'], square_size):\n",
    "                        current_time = time.time()\n",
    "                        if not finger_in_box[element]:\n",
    "                            print(f\"Touch detected in {element} square\")\n",
    "                            finger_in_box[element] = True\n",
    "                            if current_time - last_sound_time[element] > 1:  # 1 second cooldown\n",
    "                                print(f\"Attempting to play sound for {element}\")\n",
    "                                play_sound(info['sound'])\n",
    "                                last_sound_time[element] = current_time\n",
    "                        if hand_closed and not grabbed_word:\n",
    "                            grabbed_word = element\n",
    "                    else:\n",
    "                        finger_in_box[element] = False\n",
    "\n",
    "    # Check if all words are in the gold box\n",
    "    if not gold_achieved:\n",
    "        words_in_gold = sum(1 for word, pos in word_positions.items() if is_point_in_box(pos, gold_box['position'], square_size))\n",
    "        if words_in_gold == 4:\n",
    "            gold_achieved = True\n",
    "            word_positions.clear()  # Erase all words\n",
    "\n",
    "    # Draw words at their current positions or \"Gold\" if achieved\n",
    "    if gold_achieved:\n",
    "        gold_text_pos = get_centered_text_position(\"Gold\", gold_box['position'], square_size)\n",
    "        cv2.putText(image, \"Gold\", gold_text_pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    else:\n",
    "        for element, position in word_positions.items():\n",
    "            cv2.putText(image, element, position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)  # Stop any ongoing sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Eureka\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touch detected in Fire square\n",
      "Attempting to play sound for Fire\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    'Fire': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "    'Air': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    'Water': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    'Earth': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# Define gold box\n",
    "gold_box = {'color': (0, 215, 255), 'position': ((width - square_size) // 2, height - square_size)}\n",
    "\n",
    "# Eureka sound\n",
    "eureka_sound = 'C:/Users/dsrus/Desktop/Workspace/MTLiens/Eureka.wav'\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "if not os.path.exists(eureka_sound):\n",
    "    print(f\"Warning: Eureka sound file not found: {eureka_sound}\")\n",
    "\n",
    "# To keep track of which sounds have been played and finger position\n",
    "sound_played = {element: False for element in squares}\n",
    "finger_in_box = {element: False for element in squares}\n",
    "last_sound_time = {element: 0 for element in squares}\n",
    "\n",
    "# Word grabbing and moving\n",
    "grabbed_word = None\n",
    "\n",
    "# Function to get centered text position\n",
    "def get_centered_text_position(text, box_position, box_size):\n",
    "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "    text_x = box_position[0] + (box_size - text_size[0]) // 2\n",
    "    text_y = box_position[1] + (box_size + text_size[1]) // 2\n",
    "    return (text_x, text_y)\n",
    "\n",
    "# Initialize word positions at the center of each box\n",
    "word_positions = {element: get_centered_text_position(element, info['position'], square_size) for element, info in squares.items()}\n",
    "\n",
    "def is_hand_closed(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "def is_point_in_box(point, box_position, box_size):\n",
    "    return (box_position[0] < point[0] < box_position[0] + box_size and\n",
    "            box_position[1] < point[1] < box_position[1] + box_size)\n",
    "\n",
    "gold_achieved = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Convert back to BGR for OpenCV display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    for element, info in squares.items():\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "\n",
    "    # Draw gold box\n",
    "    overlay = image.copy()\n",
    "    cv2.rectangle(overlay, gold_box['position'], (gold_box['position'][0] + square_size, gold_box['position'][1] + square_size), gold_box['color'], -1)\n",
    "    cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "            \n",
    "            index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "\n",
    "            hand_closed = is_hand_closed(hand_landmarks)\n",
    "\n",
    "            if grabbed_word:\n",
    "                if hand_closed:\n",
    "                    word_positions[grabbed_word] = (x, y)\n",
    "                else:\n",
    "                    grabbed_word = None\n",
    "            else:\n",
    "                for element, info in squares.items():\n",
    "                    if is_point_in_box((x, y), info['position'], square_size):\n",
    "                        current_time = time.time()\n",
    "                        if not finger_in_box[element]:\n",
    "                            print(f\"Touch detected in {element} square\")\n",
    "                            finger_in_box[element] = True\n",
    "                            if current_time - last_sound_time[element] > 1:  # 1 second cooldown\n",
    "                                print(f\"Attempting to play sound for {element}\")\n",
    "                                play_sound(info['sound'])\n",
    "                                last_sound_time[element] = current_time\n",
    "                        if hand_closed and not grabbed_word:\n",
    "                            grabbed_word = element\n",
    "                    else:\n",
    "                        finger_in_box[element] = False\n",
    "\n",
    "    # Check if all words are in the gold box\n",
    "    if not gold_achieved:\n",
    "        words_in_gold = sum(1 for word, pos in word_positions.items() if is_point_in_box(pos, gold_box['position'], square_size))\n",
    "        if words_in_gold == 4:\n",
    "            gold_achieved = True\n",
    "            word_positions.clear()  # Erase all words\n",
    "            play_sound(eureka_sound)  # Play the Eureka sound\n",
    "\n",
    "    # Draw words at their current positions or \"Gold\" if achieved\n",
    "    if gold_achieved:\n",
    "        gold_text_pos = get_centered_text_position(\"Gold\", gold_box['position'], square_size)\n",
    "        cv2.putText(image, \"Gold\", gold_text_pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    else:\n",
    "        for element, position in word_positions.items():\n",
    "            cv2.putText(image, element, position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)  # Stop any ongoing sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Emoji's, but weird color thing\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    '': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "    '': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    '': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    '': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# Define gold box\n",
    "gold_box = {'color': (0, 215, 255), 'position': ((width - square_size) // 2, height - square_size)}\n",
    "\n",
    "# Eureka sound\n",
    "eureka_sound = 'C:/Users/dsrus/Desktop/Workspace/MTLiens/Eureka.wav'\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "if not os.path.exists(eureka_sound):\n",
    "    print(f\"Warning: Eureka sound file not found: {eureka_sound}\")\n",
    "\n",
    "# To keep track of which sounds have been played and finger position\n",
    "sound_played = {element: False for element in squares}\n",
    "finger_in_box = {element: False for element in squares}\n",
    "last_sound_time = {element: 0 for element in squares}\n",
    "\n",
    "# Word grabbing and moving\n",
    "grabbed_word = None\n",
    "\n",
    "# Initialize word positions at the center of each box\n",
    "word_positions = {element: (info['position'][0] + square_size // 2, info['position'][1] + square_size // 2) for element, info in squares.items()}\n",
    "\n",
    "def is_hand_closed(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "def is_point_in_box(point, box_position, box_size):\n",
    "    return (box_position[0] < point[0] < box_position[0] + box_size and\n",
    "            box_position[1] < point[1] < box_position[1] + box_size)\n",
    "\n",
    "gold_achieved = False\n",
    "\n",
    "# Load a font that supports emoji\n",
    "font = ImageFont.truetype(\"seguiemj.ttf\", 40)  # You may need to specify the full path to the font file\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Convert back to BGR for OpenCV display\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    for element, info in squares.items():\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "\n",
    "    # Draw gold box\n",
    "    overlay = image.copy()\n",
    "    cv2.rectangle(overlay, gold_box['position'], (gold_box['position'][0] + square_size, gold_box['position'][1] + square_size), gold_box['color'], -1)\n",
    "    cv2.addWeighted(overlay, 0.25, image, 0.75, 0, image)\n",
    "\n",
    "    # Convert the image to PIL Image for drawing emoji\n",
    "    pil_image = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "            \n",
    "            index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "\n",
    "            hand_closed = is_hand_closed(hand_landmarks)\n",
    "\n",
    "            if grabbed_word:\n",
    "                if hand_closed:\n",
    "                    word_positions[grabbed_word] = (x, y)\n",
    "                else:\n",
    "                    grabbed_word = None\n",
    "            else:\n",
    "                for element, info in squares.items():\n",
    "                    if is_point_in_box((x, y), info['position'], square_size):\n",
    "                        current_time = time.time()\n",
    "                        if not finger_in_box[element]:\n",
    "                            print(f\"Touch detected in {element} square\")\n",
    "                            finger_in_box[element] = True\n",
    "                            if current_time - last_sound_time[element] > 1:  # 1 second cooldown\n",
    "                                print(f\"Attempting to play sound for {element}\")\n",
    "                                play_sound(info['sound'])\n",
    "                                last_sound_time[element] = current_time\n",
    "                        if hand_closed and not grabbed_word:\n",
    "                            grabbed_word = element\n",
    "                    else:\n",
    "                        finger_in_box[element] = False\n",
    "\n",
    "    # Check if all words are in the gold box\n",
    "    if not gold_achieved:\n",
    "        words_in_gold = sum(1 for word, pos in word_positions.items() if is_point_in_box(pos, gold_box['position'], square_size))\n",
    "        if words_in_gold == 4:\n",
    "            gold_achieved = True\n",
    "            word_positions.clear()  # Erase all words\n",
    "            play_sound(eureka_sound)  # Play the Eureka sound\n",
    "\n",
    "    # Draw words at their current positions or \"Gold\" if achieved\n",
    "    if gold_achieved:\n",
    "        draw.text((gold_box['position'][0] + square_size // 2, gold_box['position'][1] + square_size // 2), \"Gold\", font=font, fill=(255, 255, 255), anchor=\"mm\")\n",
    "    else:\n",
    "        for element, position in word_positions.items():\n",
    "            draw.text(position, element, font=font, fill=(255, 255, 255), anchor=\"mm\")\n",
    "\n",
    "    # Convert PIL Image back to OpenCV image\n",
    "    image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)  # Stop any ongoing sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Emoji Font, fixed?\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touch detected in  square\n",
      "Attempting to play sound for \n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import emoji\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    '': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "    '': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    '': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    '': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# Define gold box\n",
    "gold_box = {'color': (0, 215, 255), 'position': ((width - square_size) // 2, height - square_size)}\n",
    "\n",
    "# Eureka sound\n",
    "eureka_sound = 'C:/Users/dsrus/Desktop/Workspace/MTLiens/Eureka.wav'\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "if not os.path.exists(eureka_sound):\n",
    "    print(f\"Warning: Eureka sound file not found: {eureka_sound}\")\n",
    "\n",
    "# To keep track of which sounds have been played and finger position\n",
    "sound_played = {element: False for element in squares}\n",
    "finger_in_box = {element: False for element in squares}\n",
    "last_sound_time = {element: 0 for element in squares}\n",
    "\n",
    "# Word grabbing and moving\n",
    "grabbed_word = None\n",
    "\n",
    "# Initialize word positions at the center of each box\n",
    "word_positions = {element: (info['position'][0] + square_size // 2, info['position'][1] + square_size // 2) for element, info in squares.items()}\n",
    "\n",
    "def is_hand_closed(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "def is_point_in_box(point, box_position, box_size):\n",
    "    return (box_position[0] < point[0] < box_position[0] + box_size and\n",
    "            box_position[1] < point[1] < box_position[1] + box_size)\n",
    "\n",
    "gold_achieved = False\n",
    "\n",
    "# Prepare emoji images\n",
    "emoji_images = {}\n",
    "for element in squares.keys():\n",
    "    emoji_img = emoji.emojize(element, language='alias')\n",
    "    emoji_images[element] = Image.new('RGBA', (64, 64), (255, 255, 255, 0))\n",
    "    d = ImageDraw.Draw(emoji_images[element])\n",
    "    d.text((32, 32), emoji_img, font=ImageFont.truetype(\"seguiemj.ttf\", 48), fill=(0, 0, 0, 255), anchor=\"mm\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    overlay = image_rgb.copy()\n",
    "    for element, info in squares.items():\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "    cv2.addWeighted(overlay, 0.25, image_rgb, 0.75, 0, image_rgb)\n",
    "\n",
    "    # Draw gold box\n",
    "    cv2.rectangle(overlay, gold_box['position'], (gold_box['position'][0] + square_size, gold_box['position'][1] + square_size), gold_box['color'], -1)\n",
    "    cv2.addWeighted(overlay, 0.25, image_rgb, 0.75, 0, image_rgb)\n",
    "\n",
    "    # Convert the image to PIL Image for drawing emoji\n",
    "    pil_image = Image.fromarray(image_rgb)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image_rgb, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "            )\n",
    "            \n",
    "            index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "\n",
    "            hand_closed = is_hand_closed(hand_landmarks)\n",
    "\n",
    "            if grabbed_word:\n",
    "                if hand_closed:\n",
    "                    word_positions[grabbed_word] = (x, y)\n",
    "                else:\n",
    "                    grabbed_word = None\n",
    "            else:\n",
    "                for element, info in squares.items():\n",
    "                    if is_point_in_box((x, y), info['position'], square_size):\n",
    "                        current_time = time.time()\n",
    "                        if not finger_in_box[element]:\n",
    "                            print(f\"Touch detected in {element} square\")\n",
    "                            finger_in_box[element] = True\n",
    "                            if current_time - last_sound_time[element] > 1:  # 1 second cooldown\n",
    "                                print(f\"Attempting to play sound for {element}\")\n",
    "                                play_sound(info['sound'])\n",
    "                                last_sound_time[element] = current_time\n",
    "                        if hand_closed and not grabbed_word:\n",
    "                            grabbed_word = element\n",
    "                    else:\n",
    "                        finger_in_box[element] = False\n",
    "\n",
    "    # Check if all words are in the gold box\n",
    "    if not gold_achieved:\n",
    "        words_in_gold = sum(1 for word, pos in word_positions.items() if is_point_in_box(pos, gold_box['position'], square_size))\n",
    "        if words_in_gold == 4:\n",
    "            gold_achieved = True\n",
    "            word_positions.clear()  # Erase all words\n",
    "            play_sound(eureka_sound)  # Play the Eureka sound\n",
    "\n",
    "    # Draw words at their current positions or \"Gold\" if achieved\n",
    "    if gold_achieved:\n",
    "        draw = ImageDraw.Draw(pil_image)\n",
    "        draw.text((gold_box['position'][0] + square_size // 2, gold_box['position'][1] + square_size // 2), \"Gold\", font=ImageFont.truetype(\"arial.ttf\", 40), fill=(255, 255, 255), anchor=\"mm\")\n",
    "    else:\n",
    "        for element, position in word_positions.items():\n",
    "            pil_image.paste(emoji_images[element], (int(position[0] - 32), int(position[1] - 32)), emoji_images[element])\n",
    "\n",
    "    # Convert PIL Image back to OpenCV image (RGB)\n",
    "    image_rgb = np.array(pil_image)\n",
    "\n",
    "    # Convert RGB to BGR for display\n",
    "    image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image_bgr)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)  # Stop any ongoing sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Pretty good, with 'r' reset\\\\ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touch detected in :fire: square\n",
      "Attempting to play sound for :fire:\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav\n",
      "Touch detected in :dash: square\n",
      "Attempting to play sound for :dash:\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav\n",
      "Touch detected in :ocean: square\n",
      "Attempting to play sound for :ocean:\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav\n",
      "Touch detected in :seedling: square\n",
      "Attempting to play sound for :seedling:\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/Eureka.wav\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import emoji\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to play sound asynchronously\n",
    "def play_sound(sound_file):\n",
    "    def play():\n",
    "        try:\n",
    "            if not os.path.exists(sound_file):\n",
    "                print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                return\n",
    "            winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "            print(f\"Played sound: {sound_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "    threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Define squares\n",
    "square_size = min(width, height) // 4\n",
    "squares = {\n",
    "    ':fire:': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "    ':dash:': {'color': (255, 255, 0), 'position': (width - square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "    ':ocean:': {'color': (255, 0, 0), 'position': (0, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "    ':seedling:': {'color': (0, 128, 128), 'position': (width - square_size, height - square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "}\n",
    "\n",
    "# Define gold box\n",
    "gold_box = {'color': (0, 215, 255), 'position': ((width - square_size) // 2, height - square_size)}\n",
    "\n",
    "# Eureka sound\n",
    "eureka_sound = 'C:/Users/dsrus/Desktop/Workspace/MTLiens/Eureka.wav'\n",
    "\n",
    "# Check if sound files exist\n",
    "for element, info in squares.items():\n",
    "    if not os.path.exists(info['sound']):\n",
    "        print(f\"Warning: Sound file not found for {element}: {info['sound']}\")\n",
    "\n",
    "if not os.path.exists(eureka_sound):\n",
    "    print(f\"Warning: Eureka sound file not found: {eureka_sound}\")\n",
    "\n",
    "# To keep track of which sounds have been played and finger position\n",
    "sound_played = {element: False for element in squares}\n",
    "finger_in_box = {element: False for element in squares}\n",
    "last_sound_time = {element: 0 for element in squares}\n",
    "\n",
    "# Word grabbing and moving\n",
    "grabbed_word = None\n",
    "\n",
    "# Initialize word positions at the center of each box\n",
    "def reset_word_positions():\n",
    "    global word_positions, gold_achieved, grabbed_word\n",
    "    word_positions = {element: (info['position'][0] + square_size // 2, info['position'][1] + square_size // 2) for element, info in squares.items()}\n",
    "    gold_achieved = False\n",
    "    grabbed_word = None\n",
    "\n",
    "reset_word_positions()\n",
    "\n",
    "def is_hand_closed(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "def is_point_in_box(point, box_position, box_size):\n",
    "    return (box_position[0] < point[0] < box_position[0] + box_size and\n",
    "            box_position[1] < point[1] < box_position[1] + box_size)\n",
    "\n",
    "# Prepare emoji images\n",
    "emoji_font = ImageFont.truetype(\"seguiemj.ttf\", 48)\n",
    "emoji_images = {}\n",
    "for element in squares.keys():\n",
    "    emoji_char = emoji.emojize(element, language='alias')\n",
    "    emoji_images[element] = Image.new('RGBA', (64, 64), (255, 255, 255, 0))\n",
    "    d = ImageDraw.Draw(emoji_images[element])\n",
    "    d.text((32, 32), emoji_char, font=emoji_font, fill=(0, 0, 0, 255), anchor=\"mm\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Mirror the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    # Draw squares and labels\n",
    "    overlay = image_rgb.copy()\n",
    "    for element, info in squares.items():\n",
    "        cv2.rectangle(overlay, info['position'], (info['position'][0] + square_size, info['position'][1] + square_size), info['color'], -1)\n",
    "    cv2.addWeighted(overlay, 0.25, image_rgb, 0.75, 0, image_rgb)\n",
    "\n",
    "    # Draw gold box\n",
    "    cv2.rectangle(overlay, gold_box['position'], (gold_box['position'][0] + square_size, gold_box['position'][1] + square_size), gold_box['color'], -1)\n",
    "    cv2.addWeighted(overlay, 0.25, image_rgb, 0.75, 0, image_rgb)\n",
    "\n",
    "    # Convert the image to PIL Image for drawing emoji\n",
    "    pil_image = Image.fromarray(image_rgb)\n",
    "\n",
    "    # Draw hand landmarks and check for touches\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image_rgb, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "            )\n",
    "            \n",
    "            index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            x, y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "\n",
    "            hand_closed = is_hand_closed(hand_landmarks)\n",
    "\n",
    "            if grabbed_word:\n",
    "                if hand_closed:\n",
    "                    word_positions[grabbed_word] = (x, y)\n",
    "                else:\n",
    "                    grabbed_word = None\n",
    "            else:\n",
    "                for element, info in squares.items():\n",
    "                    if is_point_in_box((x, y), info['position'], square_size):\n",
    "                        current_time = time.time()\n",
    "                        if not finger_in_box[element]:\n",
    "                            print(f\"Touch detected in {element} square\")\n",
    "                            finger_in_box[element] = True\n",
    "                            if current_time - last_sound_time[element] > 1:  # 1 second cooldown\n",
    "                                print(f\"Attempting to play sound for {element}\")\n",
    "                                play_sound(info['sound'])\n",
    "                                last_sound_time[element] = current_time\n",
    "                        if hand_closed and not grabbed_word:\n",
    "                            grabbed_word = element\n",
    "                    else:\n",
    "                        finger_in_box[element] = False\n",
    "\n",
    "    # Check if all words are in the gold box\n",
    "    if not gold_achieved:\n",
    "        words_in_gold = sum(1 for word, pos in word_positions.items() if is_point_in_box(pos, gold_box['position'], square_size))\n",
    "        if words_in_gold == 4:\n",
    "            gold_achieved = True\n",
    "            word_positions.clear()  # Erase all words\n",
    "            play_sound(eureka_sound)  # Play the Eureka sound\n",
    "\n",
    "    # Draw words at their current positions or \"Gold\" if achieved\n",
    "    if gold_achieved:\n",
    "        draw = ImageDraw.Draw(pil_image)\n",
    "        draw.text((gold_box['position'][0] + square_size // 2, gold_box['position'][1] + square_size // 2), \"Gold\", font=ImageFont.truetype(\"arial.ttf\", 40), fill=(255, 255, 255), anchor=\"mm\")\n",
    "    else:\n",
    "        for element, position in word_positions.items():\n",
    "            emoji_char = emoji.emojize(element, language='alias')\n",
    "            draw = ImageDraw.Draw(pil_image)\n",
    "            draw.text((position[0], position[1]), emoji_char, font=emoji_font, fill=(255, 255, 255), anchor=\"mm\")\n",
    "\n",
    "    # Convert PIL Image back to OpenCV image (RGB)\n",
    "    image_rgb = np.array(pil_image)\n",
    "\n",
    "    # Convert RGB to BGR for display\n",
    "    image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Display the image in its own window\n",
    "    cv2.imshow('Element Squares', image_bgr)\n",
    "\n",
    "    # Check for key presses\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):\n",
    "        reset_word_positions()\n",
    "        print(\"Game reset!\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)  # Stop any ongoing sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//General MediaPipe mask test\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Selfie Segmentation\n",
    "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "selfie_segmentation = mp_selfie_segmentation.SelfieSegmentation(model_selection=0)\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    # Convert the BGR image to RGB\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and get the segmentation mask\n",
    "    results = selfie_segmentation.process(rgb_image)\n",
    "\n",
    "    # Create a blue color image\n",
    "    blue_color = np.zeros(image.shape, dtype=np.uint8)\n",
    "    blue_color[:] = (255, 0, 0)  # BGR format\n",
    "\n",
    "    # Create the segmentation mask image\n",
    "    segmentation_mask = results.segmentation_mask\n",
    "\n",
    "    # Ensure the mask has 3 channels like the image\n",
    "    segmentation_mask_3channel = np.stack((segmentation_mask,)*3, axis=-1)\n",
    "\n",
    "    # Blend the original image with the blue color based on the mask\n",
    "    output_image = np.where(segmentation_mask_3channel > 0.1, \n",
    "                            cv2.addWeighted(image, 0.5, blue_color, 0.5, 0), \n",
    "                            image)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Selfie Segmentation', output_image)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == 27:  # Press 'ESC' to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Final, extra emoji thing but wtv\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touch detected in :ocean: square\n",
      "Attempting to play sound for :ocean:\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav\n",
      "Switched to mask view\n",
      "Switched to game view\n",
      "Switched to mask view\n",
      "Switched to game view\n",
      "Switched to mask view\n",
      "Switched to game view\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import emoji\n",
    "\n",
    "class ElementGame:\n",
    "    def __init__(self, cap, width, height):\n",
    "        self.cap = cap\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.square_size = min(width, height) // 4\n",
    "        \n",
    "        # Initialize MediaPipe Hands\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "        \n",
    "        # Initialize drawing utilities\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        \n",
    "        self.squares = {\n",
    "            ':fire:': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "            ':dash:': {'color': (255, 255, 0), 'position': (width - self.square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "            ':ocean:': {'color': (255, 0, 0), 'position': (0, height - self.square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "            ':seedling:': {'color': (0, 128, 128), 'position': (width - self.square_size, height - self.square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "        }\n",
    "        \n",
    "        self.gold_box = {'color': (0, 215, 255), 'position': ((width - self.square_size) // 2, height - self.square_size)}\n",
    "        self.eureka_sound = 'C:/Users/dsrus/Desktop/Workspace/MTLiens/Eureka.wav'\n",
    "        \n",
    "        self.sound_played = {element: False for element in self.squares}\n",
    "        self.finger_in_box = {element: False for element in self.squares}\n",
    "        self.last_sound_time = {element: 0 for element in self.squares}\n",
    "        \n",
    "        self.grabbed_word = None\n",
    "        self.gold_achieved = False\n",
    "        self.mask_color = None\n",
    "        \n",
    "        self.reset_word_positions()\n",
    "        \n",
    "        self.emoji_font = ImageFont.truetype(\"seguiemj.ttf\", 48)\n",
    "        self.emoji_images = self.prepare_emoji_images()\n",
    "\n",
    "    def reset_word_positions(self):\n",
    "        self.word_positions = {element: (info['position'][0] + self.square_size // 2, info['position'][1] + self.square_size // 2) \n",
    "                               for element, info in self.squares.items()}\n",
    "        self.gold_achieved = False\n",
    "        self.grabbed_word = None\n",
    "        self.mask_color = None\n",
    "\n",
    "    def is_hand_closed(self, hand_landmarks):\n",
    "        thumb_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.THUMB_TIP]\n",
    "        index_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "    def is_point_in_box(self, point, box_position, box_size):\n",
    "        return (box_position[0] < point[0] < box_position[0] + box_size and\n",
    "                box_position[1] < point[1] < box_position[1] + box_size)\n",
    "\n",
    "    def prepare_emoji_images(self):\n",
    "        emoji_images = {}\n",
    "        for element in self.squares.keys():\n",
    "            emoji_char = emoji.emojize(element, language='alias')\n",
    "            emoji_images[element] = Image.new('RGBA', (64, 64), (255, 255, 255, 0))\n",
    "            d = ImageDraw.Draw(emoji_images[element])\n",
    "            d.text((32, 32), emoji_char, font=self.emoji_font, fill=(0, 0, 0, 255), anchor=\"mm\")\n",
    "        return emoji_images\n",
    "\n",
    "    def play_sound(self, sound_file):\n",
    "        def play():\n",
    "            try:\n",
    "                if not os.path.exists(sound_file):\n",
    "                    print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                    return\n",
    "                winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "                print(f\"Played sound: {sound_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "        threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.hands.process(image_rgb)\n",
    "\n",
    "        overlay = image_rgb.copy()\n",
    "        for element, info in self.squares.items():\n",
    "            cv2.rectangle(overlay, info['position'], \n",
    "                          (info['position'][0] + self.square_size, info['position'][1] + self.square_size), \n",
    "                          info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image_rgb, 0.75, 0, image_rgb)\n",
    "\n",
    "        cv2.rectangle(overlay, self.gold_box['position'], \n",
    "                      (self.gold_box['position'][0] + self.square_size, self.gold_box['position'][1] + self.square_size), \n",
    "                      self.gold_box['color'] if self.mask_color is None else self.mask_color, -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image_rgb, 0.75, 0, image_rgb)\n",
    "\n",
    "        pil_image = Image.fromarray(image_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    image_rgb, hand_landmarks, self.mp_hands.HAND_CONNECTIONS,\n",
    "                    self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                    self.mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "                )\n",
    "                \n",
    "                index_finger_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                x, y = int(index_finger_tip.x * self.width), int(index_finger_tip.y * self.height)\n",
    "\n",
    "                hand_closed = self.is_hand_closed(hand_landmarks)\n",
    "\n",
    "                if self.grabbed_word:\n",
    "                    if hand_closed:\n",
    "                        self.word_positions[self.grabbed_word] = (x, y)\n",
    "                    else:\n",
    "                        if self.is_point_in_box((x, y), self.gold_box['position'], self.square_size):\n",
    "                            self.mask_color = self.squares[self.grabbed_word]['color']\n",
    "                            self.gold_box['color'] = self.mask_color\n",
    "                        self.grabbed_word = None\n",
    "                else:\n",
    "                    for element, info in self.squares.items():\n",
    "                        if self.is_point_in_box((x, y), info['position'], self.square_size):\n",
    "                            current_time = time.time()\n",
    "                            if not self.finger_in_box[element]:\n",
    "                                print(f\"Touch detected in {element} square\")\n",
    "                                self.finger_in_box[element] = True\n",
    "                                if current_time - self.last_sound_time[element] > 1:  # 1 second cooldown\n",
    "                                    print(f\"Attempting to play sound for {element}\")\n",
    "                                    self.play_sound(info['sound'])\n",
    "                                    self.last_sound_time[element] = current_time\n",
    "                            if hand_closed and not self.grabbed_word:\n",
    "                                self.grabbed_word = element\n",
    "                        else:\n",
    "                            self.finger_in_box[element] = False\n",
    "\n",
    "        for element, position in self.word_positions.items():\n",
    "            emoji_char = emoji.emojize(element, language='alias')\n",
    "            draw = ImageDraw.Draw(pil_image)\n",
    "            draw.text((position[0], position[1]), emoji_char, font=self.emoji_font, fill=(255, 255, 255), anchor=\"mm\")\n",
    "\n",
    "        return np.array(pil_image)\n",
    "\n",
    "class CameraManager:\n",
    "    def __init__(self, cap):\n",
    "        self.cap = cap\n",
    "        self.is_game_view = True\n",
    "        self.mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "        self.selfie_segmentation = self.mp_selfie_segmentation.SelfieSegmentation(model_selection=0)\n",
    "\n",
    "    def switch_view(self):\n",
    "        self.is_game_view = not self.is_game_view\n",
    "        print(f\"Switched to {'game' if self.is_game_view else 'mask'} view\")\n",
    "\n",
    "    def apply_mask(self, frame, mask_color):\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.selfie_segmentation.process(image_rgb)\n",
    "        condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "        if mask_color is not None:\n",
    "            overlay = np.zeros(image_rgb.shape, dtype=np.uint8)\n",
    "            overlay[:] = mask_color\n",
    "            overlay = cv2.addWeighted(image_rgb, 0.8, overlay, 0.2, 0)\n",
    "            image_rgb = np.where(condition, overlay, image_rgb)\n",
    "        return image_rgb\n",
    "\n",
    "class MainProgram:\n",
    "    def __init__(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        ret, frame = self.cap.read()\n",
    "        self.height, self.width = frame.shape[:2]\n",
    "        self.game = ElementGame(self.cap, self.width, self.height)\n",
    "        self.camera_manager = CameraManager(self.cap)\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to capture frame\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            if self.camera_manager.is_game_view:\n",
    "                image_rgb = self.game.process_frame(frame)\n",
    "            else:\n",
    "                image_rgb = self.camera_manager.apply_mask(frame, self.game.mask_color)\n",
    "\n",
    "            image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imshow('Camera View', image_bgr)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('r'):\n",
    "                self.game.reset_word_positions()\n",
    "                print(\"Game reset!\")\n",
    "            elif key == ord('s'):\n",
    "                self.camera_manager.switch_view()\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        winsound.PlaySound(None, winsound.SND_PURGE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    program = MainProgram()\n",
    "    program.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Mask immediate\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touch detected in :fire: square\n",
      "Attempting to play sound for :fire:\n",
      "Switched to mask view\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav\n",
      "Switched to game view\n",
      "Touch detected in :ocean: square\n",
      "Attempting to play sound for :ocean:\n",
      "Switched to mask view\n",
      "Switched to game view\n",
      "Switched to mask view\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav\n",
      "Switched to game view\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import emoji\n",
    "\n",
    "class ElementGame:\n",
    "    def __init__(self, cap, width, height):\n",
    "        self.cap = cap\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.square_size = min(width, height) // 4\n",
    "        \n",
    "        # Initialize MediaPipe Hands\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "        \n",
    "        # Initialize MediaPipe Selfie Segmentation\n",
    "        self.mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "        self.selfie_segmentation = self.mp_selfie_segmentation.SelfieSegmentation(model_selection=0)\n",
    "        \n",
    "        # Initialize drawing utilities\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        \n",
    "        self.squares = {\n",
    "            ':fire:': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "            ':dash:': {'color': (255, 255, 0), 'position': (width - self.square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "            ':ocean:': {'color': (255, 0, 0), 'position': (0, height - self.square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "            ':seedling:': {'color': (0, 128, 128), 'position': (width - self.square_size, height - self.square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "        }\n",
    "        \n",
    "        self.gold_box = {'color': (0, 215, 255), 'position': ((width - self.square_size) // 2, height - self.square_size)}\n",
    "        self.eureka_sound = 'C:/Users/dsrus/Desktop/Workspace/MTLiens/Eureka.wav'\n",
    "        \n",
    "        self.sound_played = {element: False for element in self.squares}\n",
    "        self.finger_in_box = {element: False for element in self.squares}\n",
    "        self.last_sound_time = {element: 0 for element in self.squares}\n",
    "        \n",
    "        self.grabbed_word = None\n",
    "        self.gold_achieved = False\n",
    "        self.mask_color = None\n",
    "        \n",
    "        self.reset_word_positions()\n",
    "        \n",
    "        self.emoji_font = ImageFont.truetype(\"seguiemj.ttf\", 48)\n",
    "        self.emoji_images = self.prepare_emoji_images()\n",
    "\n",
    "    def reset_word_positions(self):\n",
    "        self.word_positions = {element: (info['position'][0] + self.square_size // 2, info['position'][1] + self.square_size // 2) \n",
    "                               for element, info in self.squares.items()}\n",
    "        self.gold_achieved = False\n",
    "        self.grabbed_word = None\n",
    "        self.mask_color = None\n",
    "\n",
    "    def is_hand_closed(self, hand_landmarks):\n",
    "        thumb_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.THUMB_TIP]\n",
    "        index_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "    def is_point_in_box(self, point, box_position, box_size):\n",
    "        return (box_position[0] < point[0] < box_position[0] + box_size and\n",
    "                box_position[1] < point[1] < box_position[1] + box_size)\n",
    "\n",
    "    def prepare_emoji_images(self):\n",
    "        emoji_images = {}\n",
    "        for element in self.squares.keys():\n",
    "            emoji_char = emoji.emojize(element, language='alias')\n",
    "            emoji_images[element] = Image.new('RGBA', (64, 64), (255, 255, 255, 0))\n",
    "            d = ImageDraw.Draw(emoji_images[element])\n",
    "            d.text((32, 32), emoji_char, font=self.emoji_font, fill=(0, 0, 0, 255), anchor=\"mm\")\n",
    "        return emoji_images\n",
    "\n",
    "    def play_sound(self, sound_file):\n",
    "        def play():\n",
    "            try:\n",
    "                if not os.path.exists(sound_file):\n",
    "                    print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                    return\n",
    "                winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "                print(f\"Played sound: {sound_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "        threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "    def apply_mask(self, image_rgb):\n",
    "        results = self.selfie_segmentation.process(image_rgb)\n",
    "        condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "        if self.mask_color is not None:\n",
    "            overlay = np.zeros(image_rgb.shape, dtype=np.uint8)\n",
    "            overlay[:] = self.mask_color\n",
    "            overlay = cv2.addWeighted(image_rgb, 0.8, overlay, 0.2, 0)\n",
    "            image_rgb = np.where(condition, overlay, image_rgb)\n",
    "        return image_rgb\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.hands.process(image_rgb)\n",
    "\n",
    "        # Apply mask first\n",
    "        image_rgb = self.apply_mask(image_rgb)\n",
    "\n",
    "        overlay = image_rgb.copy()\n",
    "        for element, info in self.squares.items():\n",
    "            cv2.rectangle(overlay, info['position'], \n",
    "                          (info['position'][0] + self.square_size, info['position'][1] + self.square_size), \n",
    "                          info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image_rgb, 0.75, 0, image_rgb)\n",
    "\n",
    "        cv2.rectangle(overlay, self.gold_box['position'], \n",
    "                      (self.gold_box['position'][0] + self.square_size, self.gold_box['position'][1] + self.square_size), \n",
    "                      self.gold_box['color'] if self.mask_color is None else self.mask_color, -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image_rgb, 0.75, 0, image_rgb)\n",
    "\n",
    "        pil_image = Image.fromarray(image_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    image_rgb, hand_landmarks, self.mp_hands.HAND_CONNECTIONS,\n",
    "                    self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                    self.mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "                )\n",
    "                \n",
    "                index_finger_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                x, y = int(index_finger_tip.x * self.width), int(index_finger_tip.y * self.height)\n",
    "\n",
    "                hand_closed = self.is_hand_closed(hand_landmarks)\n",
    "\n",
    "                if self.grabbed_word:\n",
    "                    if hand_closed:\n",
    "                        self.word_positions[self.grabbed_word] = (x, y)\n",
    "                    else:\n",
    "                        if self.is_point_in_box((x, y), self.gold_box['position'], self.square_size):\n",
    "                            self.mask_color = self.squares[self.grabbed_word]['color']\n",
    "                            self.gold_box['color'] = self.mask_color\n",
    "                        self.grabbed_word = None\n",
    "                else:\n",
    "                    for element, info in self.squares.items():\n",
    "                        if self.is_point_in_box((x, y), info['position'], self.square_size):\n",
    "                            current_time = time.time()\n",
    "                            if not self.finger_in_box[element]:\n",
    "                                print(f\"Touch detected in {element} square\")\n",
    "                                self.finger_in_box[element] = True\n",
    "                                if current_time - self.last_sound_time[element] > 1:  # 1 second cooldown\n",
    "                                    print(f\"Attempting to play sound for {element}\")\n",
    "                                    self.play_sound(info['sound'])\n",
    "                                    self.last_sound_time[element] = current_time\n",
    "                            if hand_closed and not self.grabbed_word:\n",
    "                                self.grabbed_word = element\n",
    "                        else:\n",
    "                            self.finger_in_box[element] = False\n",
    "\n",
    "        for element, position in self.word_positions.items():\n",
    "            emoji_char = emoji.emojize(element, language='alias')\n",
    "            draw = ImageDraw.Draw(pil_image)\n",
    "            draw.text((position[0], position[1]), emoji_char, font=self.emoji_font, fill=(255, 255, 255), anchor=\"mm\")\n",
    "\n",
    "        return np.array(pil_image)\n",
    "\n",
    "class CameraManager:\n",
    "    def __init__(self, cap):\n",
    "        self.cap = cap\n",
    "        self.is_game_view = True\n",
    "\n",
    "    def switch_view(self):\n",
    "        self.is_game_view = not self.is_game_view\n",
    "        print(f\"Switched to {'game' if self.is_game_view else 'mask'} view\")\n",
    "\n",
    "class MainProgram:\n",
    "    def __init__(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        ret, frame = self.cap.read()\n",
    "        self.height, self.width = frame.shape[:2]\n",
    "        self.game = ElementGame(self.cap, self.width, self.height)\n",
    "        self.camera_manager = CameraManager(self.cap)\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to capture frame\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            if self.camera_manager.is_game_view:\n",
    "                image_rgb = self.game.process_frame(frame)\n",
    "            else:\n",
    "                image_rgb = self.game.apply_mask(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imshow('Camera View', image_bgr)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('r'):\n",
    "                self.game.reset_word_positions()\n",
    "                print(\"Game reset!\")\n",
    "            elif key == ord('s'):\n",
    "                self.camera_manager.switch_view()\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        winsound.PlaySound(None, winsound.SND_PURGE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    program = MainProgram()\n",
    "    program.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Slight manual iteration attempt\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dsrus\\Desktop\\Workspace\\MTLiens\\pytorch_env\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touch detected in  square\n",
      "Attempting to play sound for \n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav\n",
      "Touch detected in  square\n",
      "Attempting to play sound for \n",
      "Touch detected in  square\n",
      "Touch detected in  square\n",
      "Attempting to play sound for \n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav\n",
      "Touch detected in  square\n",
      "Attempting to play sound for \n",
      "Touch detected in  square\n",
      "Played sound: C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav\n",
      "Switched to mask view\n",
      "Switched to game view\n",
      "Game reset!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import winsound\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "class ElementGame:\n",
    "    def __init__(self, cap, width, height):\n",
    "        self.cap = cap\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.square_size = min(width, height) // 4\n",
    "        \n",
    "        # Initialize MediaPipe Hands\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "        \n",
    "        # Initialize MediaPipe Selfie Segmentation\n",
    "        self.mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "        self.selfie_segmentation = self.mp_selfie_segmentation.SelfieSegmentation(model_selection=0)\n",
    "        \n",
    "        # Initialize drawing utilities\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        \n",
    "        self.squares = {\n",
    "            '': {'color': (0, 0, 255), 'position': (0, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/fire.wav'},\n",
    "            '': {'color': (255, 255, 0), 'position': (width - self.square_size, 0), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/air.wav'},\n",
    "            '': {'color': (255, 0, 0), 'position': (0, height - self.square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/water.wav'},\n",
    "            '': {'color': (0, 128, 128), 'position': (width - self.square_size, height - self.square_size), 'sound': 'C:/Users/dsrus/Desktop/Workspace/MTLiens/earth.wav'}\n",
    "        }\n",
    "        \n",
    "        self.gold_box = {'color': (0, 215, 255), 'position': ((width - self.square_size) // 2, height - self.square_size)}\n",
    "        self.eureka_sound = 'C:/Users/dsrus/Desktop/Workspace/MTLiens/Eureka.wav'\n",
    "        \n",
    "        self.sound_played = {element: False for element in self.squares}\n",
    "        self.finger_in_box = {element: False for element in self.squares}\n",
    "        self.last_sound_time = {element: 0 for element in self.squares}\n",
    "        \n",
    "        self.grabbed_word = None\n",
    "        self.gold_achieved = False\n",
    "        self.mask_color = None\n",
    "        \n",
    "        self.reset_word_positions()\n",
    "        \n",
    "        self.emoji_font = ImageFont.truetype(\"seguiemj.ttf\", 48)\n",
    "\n",
    "    def reset_word_positions(self):\n",
    "        self.word_positions = {element: (info['position'][0] + self.square_size // 2, info['position'][1] + self.square_size // 2) \n",
    "                               for element, info in self.squares.items()}\n",
    "        self.gold_achieved = False\n",
    "        self.grabbed_word = None\n",
    "        self.mask_color = None\n",
    "\n",
    "    def is_hand_closed(self, hand_landmarks):\n",
    "        thumb_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.THUMB_TIP]\n",
    "        index_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        return (thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2 < 0.01\n",
    "\n",
    "    def is_point_in_box(self, point, box_position, box_size):\n",
    "        return (box_position[0] < point[0] < box_position[0] + box_size and\n",
    "                box_position[1] < point[1] < box_position[1] + box_size)\n",
    "\n",
    "    def play_sound(self, sound_file):\n",
    "        def play():\n",
    "            try:\n",
    "                if not os.path.exists(sound_file):\n",
    "                    print(f\"Error: Sound file not found: {sound_file}\")\n",
    "                    return\n",
    "                winsound.PlaySound(sound_file, winsound.SND_FILENAME)\n",
    "                print(f\"Played sound: {sound_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error playing sound {sound_file}: {e}\")\n",
    "\n",
    "        threading.Thread(target=play, daemon=True).start()\n",
    "\n",
    "    def apply_mask(self, image_rgb):\n",
    "        results = self.selfie_segmentation.process(image_rgb)\n",
    "        condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "        if self.mask_color is not None:\n",
    "            overlay = np.zeros(image_rgb.shape, dtype=np.uint8)\n",
    "            overlay[:] = self.mask_color\n",
    "            overlay = cv2.addWeighted(image_rgb, 0.8, overlay, 0.2, 0)\n",
    "            image_rgb = np.where(condition, overlay, image_rgb)\n",
    "        return image_rgb\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.hands.process(image_rgb)\n",
    "\n",
    "        # Apply mask first\n",
    "        image_rgb = self.apply_mask(image_rgb)\n",
    "\n",
    "        overlay = image_rgb.copy()\n",
    "        for element, info in self.squares.items():\n",
    "            cv2.rectangle(overlay, info['position'], \n",
    "                          (info['position'][0] + self.square_size, info['position'][1] + self.square_size), \n",
    "                          info['color'], -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image_rgb, 0.75, 0, image_rgb)\n",
    "\n",
    "        cv2.rectangle(overlay, self.gold_box['position'], \n",
    "                      (self.gold_box['position'][0] + self.square_size, self.gold_box['position'][1] + self.square_size), \n",
    "                      self.gold_box['color'] if self.mask_color is None else self.mask_color, -1)\n",
    "        cv2.addWeighted(overlay, 0.25, image_rgb, 0.75, 0, image_rgb)\n",
    "\n",
    "        pil_image = Image.fromarray(image_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    image_rgb, hand_landmarks, self.mp_hands.HAND_CONNECTIONS,\n",
    "                    self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                    self.mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "                )\n",
    "                \n",
    "                index_finger_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                x, y = int(index_finger_tip.x * self.width), int(index_finger_tip.y * self.height)\n",
    "\n",
    "                hand_closed = self.is_hand_closed(hand_landmarks)\n",
    "\n",
    "                if self.grabbed_word:\n",
    "                    if hand_closed:\n",
    "                        self.word_positions[self.grabbed_word] = (x, y)\n",
    "                    else:\n",
    "                        if self.is_point_in_box((x, y), self.gold_box['position'], self.square_size):\n",
    "                            self.mask_color = self.squares[self.grabbed_word]['color']\n",
    "                            self.gold_box['color'] = self.mask_color\n",
    "                        self.grabbed_word = None\n",
    "                else:\n",
    "                    for element, info in self.squares.items():\n",
    "                        if self.is_point_in_box((x, y), info['position'], self.square_size):\n",
    "                            current_time = time.time()\n",
    "                            if not self.finger_in_box[element]:\n",
    "                                print(f\"Touch detected in {element} square\")\n",
    "                                self.finger_in_box[element] = True\n",
    "                                if current_time - self.last_sound_time[element] > 1:  # 1 second cooldown\n",
    "                                    print(f\"Attempting to play sound for {element}\")\n",
    "                                    self.play_sound(info['sound'])\n",
    "                                    self.last_sound_time[element] = current_time\n",
    "                            if hand_closed and not self.grabbed_word:\n",
    "                                self.grabbed_word = element\n",
    "                        else:\n",
    "                            self.finger_in_box[element] = False\n",
    "\n",
    "        for element, position in self.word_positions.items():\n",
    "            draw = ImageDraw.Draw(pil_image)\n",
    "            draw.text((position[0], position[1]), element, font=self.emoji_font, fill=(255, 255, 255), anchor=\"mm\")\n",
    "\n",
    "        return np.array(pil_image)\n",
    "\n",
    "class CameraManager:\n",
    "    def __init__(self, cap):\n",
    "        self.cap = cap\n",
    "        self.is_game_view = True\n",
    "\n",
    "    def switch_view(self):\n",
    "        self.is_game_view = not self.is_game_view\n",
    "        print(f\"Switched to {'game' if self.is_game_view else 'mask'} view\")\n",
    "\n",
    "class MainProgram:\n",
    "    def __init__(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        ret, frame = self.cap.read()\n",
    "        self.height, self.width = frame.shape[:2]\n",
    "        self.game = ElementGame(self.cap, self.width, self.height)\n",
    "        self.camera_manager = CameraManager(self.cap)\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to capture frame\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            if self.camera_manager.is_game_view:\n",
    "                image_rgb = self.game.process_frame(frame)\n",
    "            else:\n",
    "                image_rgb = self.game.apply_mask(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imshow('Camera View', image_bgr)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('r'):\n",
    "                self.game.reset_word_positions()\n",
    "                print(\"Game reset!\")\n",
    "            elif key == ord('s'):\n",
    "                self.camera_manager.switch_view()\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        winsound.PlaySound(None, winsound.SND_PURGE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    program = MainProgram()\n",
    "    program.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
